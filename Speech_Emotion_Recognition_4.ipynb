{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from scipy.io import wavfile\n",
        "import os.path\n",
        "import IPython.display\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "import warnings"
      ],
      "metadata": {
        "id": "ia-kxB92fN7m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYqfTVd-ACo1",
        "outputId": "308e44c4-0bd8-4721-9c5d-abe5642e37a8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import wave\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio, display\n",
        "import librosa as lib\n",
        "import librosa.display\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Ep1fpfSEWa",
        "outputId": "22432733-a423-4154-a743-5f4ca61d102f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "23ihbA4UQk6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef61b522-8bcf-4e6f-ac37-8707c83a8b8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/Colab-Notebooks/Crema\"\n",
        "AUDIO_PATH = \"/content/drive/MyDrive/Colab-Notebooks/Crema/1001_DFA_ANG_XX.wav\""
      ],
      "metadata": {
        "id": "bG0Iuy17RwCX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zeroCrossingRate(audio):\n",
        "  return lib.feature.zero_crossing_rate(audio).mean()"
      ],
      "metadata": {
        "id": "hZRUzrRHI3x4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def energy(audio):\n",
        "  # using a spectrogram will give a more accurate representation\n",
        "  # of energy over time because its frames can be windowed\n",
        "  S, phase = lib.magphase(lib.stft(audio))\n",
        "  return lib.feature.rms(S=S).mean()"
      ],
      "metadata": {
        "id": "YUj1b0stI8Jp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def melSpectrogram(audio, sr):\n",
        "  mel_spectrogram = lib.feature.melspectrogram(y=audio, sr=sr, n_fft=200)\n",
        "  log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
        "  return log_mel_spectrogram"
      ],
      "metadata": {
        "id": "t03kfNaMJEUx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chromaStft(audio, sr):\n",
        "  stft = np.abs(librosa.stft(audio))\n",
        "  return librosa.feature.chroma_stft(S=stft, sr=sr, n_fft=200).mean()"
      ],
      "metadata": {
        "id": "RFqdKI4dj-sx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mfcc(data, sr):\n",
        "  return librosa.feature.mfcc(y=data, sr=sr, n_fft=200).mean()"
      ],
      "metadata": {
        "id": "bwJma-zak5ai"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tonnetz(data, sr):\n",
        "  return librosa.feature.tonnetz(y=data, sr=sr).mean();"
      ],
      "metadata": {
        "id": "fHiHGyRoqeAa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def playAudio(audio_file):\n",
        "  audio = AudioSegment.from_wav(audio_file)\n",
        "  # Play the audio\n",
        "  audio.export('temp_audio.wav', format='wav')\n",
        "  audio_data = open('temp_audio.wav', 'rb').read()\n",
        "  display(Audio(audio_data))\n",
        "  # Delete the temporary audio file\n",
        "  os.remove('temp_audio.wav')"
      ],
      "metadata": {
        "id": "GZLRcaVEinfV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_waveform(audio, sr):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(audio)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.title('Waveform')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VErUAYc_mIzR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadAndListenToAudiolib(dataset_path, class_name):\n",
        "  D, Y = [], []\n",
        "  # defining the regular expression\n",
        "  audio_files = glob.glob(os.path.join(dataset_path, f\"*{class_name}*.wav\"))\n",
        "  print(class_name)\n",
        "  # play the audio\n",
        "  '''playAudio(audio_files[0])'''\n",
        "  # plot the spectrum\n",
        "  '''audio, sr = lib.load(audio_files[0])'''\n",
        "  '''visualize_waveform(audio, sr)'''\n",
        "  # plotWaveform(audio_files[0], class_name)\n",
        "  for audio_file in audio_files: \n",
        "    # load the audio file\n",
        "    audio, sr = lib.load(audio_file)\n",
        "    # extract zero crossing rate\n",
        "    '''zcr = zeroCrossingRate(audio)'''\n",
        "    # extract energy\n",
        "    '''rms = energy(audio)'''\n",
        "    # extract mel spectrogram\n",
        "    mel_spec = melSpectrogram(audio, sr)\n",
        "    # chroma stft\n",
        "    '''cs = chromaStft(audio, sr)'''\n",
        "    '''mfc = mfcc(audio, sr)'''\n",
        "    '''ton = tonnetz(audio, sr)'''\n",
        "    # combined_features = np.concatenate(([zcr, rms], mel_spec.flatten()))\n",
        "    '''combined_features = [zcr, rms, mel_spec, cs, mfc, ton]'''\n",
        "    # print(combined_features)\n",
        "    '''D.append(combined_features)'''\n",
        "    D.append(mel_spec)\n",
        "    Y.append(class_name)\n",
        "  return D, Y"
      ],
      "metadata": {
        "id": "IsHsSI2rrbMa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadDatalib(PATH):\n",
        "  D, Y = [], []\n",
        "  classes = [\"SAD\", \"ANG\", \"DIS\", \"FEA\", \"HAP\", \"NEU\"]\n",
        "  for cls in classes: \n",
        "    d, y = loadAndListenToAudiolib(PATH, cls)\n",
        "    # D = np.concatenate((D, d))\n",
        "    D.extend(d)\n",
        "    Y = np.concatenate((Y, y))\n",
        "  return D, Y"
      ],
      "metadata": {
        "id": "sHubX5-dsmWa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cnnModel(Model):\n",
        "  def __init__(self):\n",
        "    super(cnnModel, self).__init__()\n",
        "    # Conv layer + maxpool\n",
        "    self.conv1 = Conv2D(512, 5, activation='relu')\n",
        "    self.maxpool1 = MaxPool2D(pool_size=(5, 5), strides=2)\n",
        "\n",
        "    self.conv2 = Conv2D(512, 5, activation='relu')\n",
        "    self.maxpool2 = MaxPool2D(pool_size=(5, 5), strides=2)\n",
        "\n",
        "    self.conv3 = Conv2D(128, 5, activation='relu')\n",
        "    self.maxpool3 = MaxPool2D(pool_size=(5, 5), strides=2)\n",
        "\n",
        "    #Fully connected layer\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(256, activation='relu')\n",
        "    self.d2 = Dense(6, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)"
      ],
      "metadata": {
        "id": "PkmB4uyIjwr8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnnModel()"
      ],
      "metadata": {
        "id": "zmlzwjt-ZnMP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "jaP3SwxPZnJo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "metadata": {
        "id": "JAkmUysSh2ei"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(audio, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(audio, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n"
      ],
      "metadata": {
        "id": "97wWgC3Vj8LV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test_step(audio, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(audio, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n"
      ],
      "metadata": {
        "id": "Dy3kpvPvj9Fg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D, Y = loadDatalib(PATH)"
      ],
      "metadata": {
        "id": "OcBJBL3tLS2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd588ff7-d49a-45e5-8001-253d44771171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py:2157: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANG\n",
            "DIS\n",
            "FEA\n",
            "HAP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.pad(D[1], ((0, 0), (0, 256 - D[1].shape[1]))).shape"
      ],
      "metadata": {
        "id": "BbxoENaVVh-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, array in enumerate(D):\n",
        "    D[i] = np.pad(array, ((0, 0), (0, 256 - array.shape[1])))\n",
        "D = np.array(D)"
      ],
      "metadata": {
        "id": "p6is_yI1fuG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D.shape"
      ],
      "metadata": {
        "id": "srtVtP5lIdrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "id": "X6FCElq7I01d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(Y)"
      ],
      "metadata": {
        "id": "pKCQdLtHJU3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "APTvq_yvW_6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the get_dummies() method to one-hot encode the labels\n",
        "one_hot_labels = pd.get_dummies(df)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array\n",
        "one_hot_labels = one_hot_labels.to_numpy()\n",
        "\n",
        "print(one_hot_labels.shape)"
      ],
      "metadata": {
        "id": "hSuuqU8YW-pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eda827c-7f7a-4d81-9a8a-3f5720cdacf8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7442, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = one_hot_labels"
      ],
      "metadata": {
        "id": "A5oOIKMWXEyr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "id": "UfZhBxf5XQbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902d8167-0796-456c-c995-fc520441c6f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7442, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(D, Y, test_size=0.3, random_state=69, shuffle=True, stratify=Y)"
      ],
      "metadata": {
        "id": "_8p_f52KRIHo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "YpxgNsNNYY6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebc4264-cc88-4ae1-d2ef-a4f75c83c0c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5209, 128, 256, 1)\n",
            "(2233, 128, 256, 1)\n",
            "(5209, 6)\n",
            "(2233, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((5209, 128, 256, 1))\n",
        "X_test = X_test.reshape((2233, 128, 256, 1))"
      ],
      "metadata": {
        "id": "Y1sK4j5Ubnhu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unicheck = np.unique(y_test, axis=0)"
      ],
      "metadata": {
        "id": "MNkEcVh8Yh9X"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unicheck"
      ],
      "metadata": {
        "id": "AVdqdhg6ZMmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00201b28-2dc0-41ac-a6a2-70ffbeb906ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)"
      ],
      "metadata": {
        "id": "_ixnamfeatY6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for audio, labels in train_ds:\n",
        "    train_step(audio, labels)\n",
        "\n",
        "  for test_audio, test_labels in test_ds:\n",
        "    test_step(test_audio, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )"
      ],
      "metadata": {
        "id": "Uj_5WxmeQzS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHLXPsRIaWrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}